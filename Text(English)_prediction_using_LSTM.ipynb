{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e4cc3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as i am training on the_great_gatsby by 'Francis Scott Key Fitzgerald', this model will predict on basically 'Fitzgeraldian tone';\n",
    "# this would predict word, as predicting sentenses means basically NLP, by tokenizing individual words not letters;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75e58ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e3a5ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6abb28bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  i\n",
      "\n",
      "in my younger and more vulnerable years my father gave me some advice\n",
      "that i’ve been turning over in my mind ever since.\n",
      "\n",
      "“whenever you feel like criticizing anyone,” he told me, “just\n",
      "remember that all the people in this world haven’t had the advantages\n",
      "that you’ve had.”\n",
      "\n",
      "he didn’t say any more, but we’ve always been unusually communicative\n",
      "in a reserved way, and i understood that he meant a great deal more\n",
      "than that. in consequence, i’m inclined to reserve all judgements, a\n",
      "habit that has opened up many curious natures to me and also made me\n",
      "the victim of not a few veteran bores. the abnormal mind is quick to\n",
      "detect and attach itself to this quality when it appears in a normal\n",
      "person, and so it came about that in college i was unjustly accused of\n",
      "being a politician, because i was privy to the secret griefs of wild,\n",
      "unknown men. most of the confidences were unsought—frequently i have\n",
      "feigned sleep, preoccupation, or a hostile levity when i realized\n"
     ]
    }
   ],
   "source": [
    "# load text by opening the file\n",
    "filename = r\"D:\\Deep Learning\\Text Prediction Using LSTM\\English Text\\the_great_gatsby.txt\"\n",
    "\n",
    "raw_text = open(filename, 'r', encoding = 'utf8').read() # contains both uppercase + lowercase alphabets, nothing wrong with this but the vocabulary gonna be very big ---> needs lots of training, to make meaningful senetences, so make everything as lowercase letters;\n",
    "raw_text = raw_text.lower() # converting into lowercase letters;\n",
    "\n",
    "print(raw_text[0 : 1000]) # printing 1st 1000 characters;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b50e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now cleaning the text, by removing the numbers;\n",
    "raw_text = \"\".join(c for c in raw_text if not c.isdigit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d813c3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "# total characters do i have in the training text : list of unique every character, as set used;\n",
    "chars = sorted(list(set(raw_text))) # including all special cahracters + space + alphabets; u may drop al of these without the alphabets using many NLP Tools;\n",
    "\n",
    "print(len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59f24879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as i am dealing with NN, this only understands the numbers, so i need to assign a unique no of every 'chars', by using the dictionary;\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars)) # creating a dictionary of characters mapped to integer values;\n",
    "\n",
    "# i also need the characters from the integers after the prediction, as we doesnot understands the numbers;\n",
    "int_to_chars = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14408542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length(total #characters) :  270108\n",
      "total vocabulary(unique characters) :  52\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print('corpus length(total #characters) : ', n_chars)\n",
    "print('total vocabulary(unique characters) : ', n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078cb34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e5ccd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ca3adfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 27005\n"
     ]
    }
   ],
   "source": [
    "seq_length = 60 \n",
    "step = 10 # from [0 to 9(total 10 tuples) --> input], 10th --> output;\n",
    "\n",
    "sentences = [] # x values\n",
    "next_chars = [] # y values, the character that follows the sentence defined as X;\n",
    "\n",
    "for i in range(0, n_chars - seq_length, step):  #step=1 means each sentence is offset just by a single letter\n",
    "    sentences.append(raw_text[i: i + seq_length])  #Sequence in\n",
    "    next_chars.append(raw_text[i + seq_length])  #Sequence out\n",
    "n_patterns = len(sentences)    \n",
    "print('Number of sequences:', n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "847556a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b404415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27005, 60, 52)\n",
      "(27005, 52)\n",
      "[[False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "   True False False False False False False False False False False False\n",
      "  False False False False]\n",
      " [False  True False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False  True False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False  True False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False  True False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False  True False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False  True False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False  True False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False]\n",
      " [False  True False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False]\n",
      " [False  True False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False]]\n"
     ]
    }
   ],
   "source": [
    "# x --> sequence / sentence;\n",
    "# y --> next value(character) that comes after the sentence;\n",
    "# reshape input to be [samples, time steps --> sequence length, features --> numbers of characters in our vocab (n_vocab)];\n",
    "\n",
    "# doing vectorization; this returns a vector for all sentences indicating the presence or ansences of a character;\n",
    "\n",
    "\n",
    "x = np.zeros((len(sentences), seq_length, n_vocab), dtype=bool)\n",
    "y = np.zeros((len(sentences), n_vocab), dtype=bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_to_int[char]] = 1\n",
    "    y[i, char_to_int[next_chars[i]]] = 1\n",
    "    \n",
    "print(x.shape) \n",
    "# (27005 --> length of senetnces, 60 --> a single sequence length, 52 --> available unique letters)\n",
    "# the vector value is either (false or true) as vectorization done;\n",
    "\n",
    "print(y.shape)\n",
    "# this is also true/false, means each one of 27005, i have 51 false and 1 true for that particular letter(ie. a), may be interpreted as one hot encoding;\n",
    "\n",
    "print(y[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da66dbe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6150b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f44d67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 60, 128)           92672     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 60, 64)            49408     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 52)                3380      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 182644 (713.45 KB)\n",
      "Trainable params: 182644 (713.45 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=(seq_length, n_vocab)))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(LSTM(64))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(n_vocab, activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da8a2ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "211/211 [==============================] - 86s 353ms/step - loss: 3.0911\n",
      "Epoch 2/10\n",
      "211/211 [==============================] - 63s 299ms/step - loss: 3.0401\n",
      "Epoch 3/10\n",
      "211/211 [==============================] - 63s 297ms/step - loss: 3.0171\n",
      "Epoch 4/10\n",
      "211/211 [==============================] - 62s 295ms/step - loss: 2.8636\n",
      "Epoch 5/10\n",
      "211/211 [==============================] - 62s 293ms/step - loss: 2.7562\n",
      "Epoch 6/10\n",
      "211/211 [==============================] - 64s 303ms/step - loss: 2.6839\n",
      "Epoch 7/10\n",
      "211/211 [==============================] - 73s 345ms/step - loss: 2.6014\n",
      "Epoch 8/10\n",
      "211/211 [==============================] - 79s 374ms/step - loss: 2.5143\n",
      "Epoch 9/10\n",
      "211/211 [==============================] - 68s 324ms/step - loss: 2.4168\n",
      "Epoch 10/10\n",
      "211/211 [==============================] - 67s 316ms/step - loss: 2.3530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\python_arpan\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=10)\n",
    "\n",
    "model.save('the_great_gatsby_10epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2011f983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading partially trained model\n",
    "from keras.models import load_model\n",
    "new_model = load_model(r\"D:\\Deep Learning\\Text Prediction Using LSTM\\English Text\\the_great_gatsby_10epochs.h5\", compile=False)\n",
    "new_model.compile('adam', loss = 'categorical_crossentropy') # u need to compile the newly loaded model, othwerwise u would not be able to evaluate or train or predict;\n",
    "\n",
    "# # seeing how your model is performing, in case u forgotten\n",
    "# results2 = new_model2.evaluate(X_test2, y_test_cat, steps = 16)\n",
    "# print(\"Validation loss & accuracy : \", results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "174bca55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "211/211 [==============================] - 69s 297ms/step - loss: 2.2992\n",
      "Epoch 2/50\n",
      "211/211 [==============================] - 62s 294ms/step - loss: 2.2432\n",
      "Epoch 3/50\n",
      "211/211 [==============================] - 62s 293ms/step - loss: 2.1897\n",
      "Epoch 4/50\n",
      "211/211 [==============================] - 62s 295ms/step - loss: 2.1407\n",
      "Epoch 5/50\n",
      "211/211 [==============================] - 63s 298ms/step - loss: 2.0929\n",
      "Epoch 6/50\n",
      "211/211 [==============================] - 64s 305ms/step - loss: 2.0476\n",
      "Epoch 7/50\n",
      "211/211 [==============================] - 71s 338ms/step - loss: 2.0088\n",
      "Epoch 8/50\n",
      "211/211 [==============================] - 75s 356ms/step - loss: 1.9625\n",
      "Epoch 9/50\n",
      "211/211 [==============================] - 71s 334ms/step - loss: 1.9191\n",
      "Epoch 10/50\n",
      "211/211 [==============================] - 68s 320ms/step - loss: 1.8744\n",
      "Epoch 11/50\n",
      "211/211 [==============================] - 66s 313ms/step - loss: 1.8354\n",
      "Epoch 12/50\n",
      "211/211 [==============================] - 63s 299ms/step - loss: 1.7942\n",
      "Epoch 13/50\n",
      "211/211 [==============================] - 64s 301ms/step - loss: 1.7472\n",
      "Epoch 14/50\n",
      "211/211 [==============================] - 63s 299ms/step - loss: 1.7028\n",
      "Epoch 15/50\n",
      "211/211 [==============================] - 63s 301ms/step - loss: 1.6545\n",
      "Epoch 16/50\n",
      "211/211 [==============================] - 63s 299ms/step - loss: 1.6069\n",
      "Epoch 17/50\n",
      "211/211 [==============================] - 64s 301ms/step - loss: 1.5605\n",
      "Epoch 18/50\n",
      "211/211 [==============================] - 63s 300ms/step - loss: 1.5124\n",
      "Epoch 19/50\n",
      "211/211 [==============================] - 63s 301ms/step - loss: 1.4606\n",
      "Epoch 20/50\n",
      "211/211 [==============================] - 63s 300ms/step - loss: 1.4031\n",
      "Epoch 21/50\n",
      "211/211 [==============================] - 64s 304ms/step - loss: 1.3564\n",
      "Epoch 22/50\n",
      "211/211 [==============================] - 63s 300ms/step - loss: 1.2910\n",
      "Epoch 23/50\n",
      "211/211 [==============================] - 63s 301ms/step - loss: 1.2416\n",
      "Epoch 24/50\n",
      "211/211 [==============================] - 63s 300ms/step - loss: 1.1856\n",
      "Epoch 25/50\n",
      "211/211 [==============================] - 63s 299ms/step - loss: 1.1293\n",
      "Epoch 26/50\n",
      "211/211 [==============================] - 63s 300ms/step - loss: 1.0695\n",
      "Epoch 27/50\n",
      "211/211 [==============================] - 64s 304ms/step - loss: 1.0158\n",
      "Epoch 28/50\n",
      "211/211 [==============================] - 63s 300ms/step - loss: 0.9606\n",
      "Epoch 29/50\n",
      "211/211 [==============================] - 63s 299ms/step - loss: 0.9176\n",
      "Epoch 30/50\n",
      "211/211 [==============================] - 63s 300ms/step - loss: 0.8516\n",
      "Epoch 31/50\n",
      "211/211 [==============================] - 63s 300ms/step - loss: 0.7963\n",
      "Epoch 32/50\n",
      "211/211 [==============================] - 64s 301ms/step - loss: 0.7409\n",
      "Epoch 33/50\n",
      "211/211 [==============================] - 63s 300ms/step - loss: 0.6953\n",
      "Epoch 34/50\n",
      "211/211 [==============================] - 63s 300ms/step - loss: 0.6551\n",
      "Epoch 35/50\n",
      "211/211 [==============================] - 64s 302ms/step - loss: 0.6070\n",
      "Epoch 36/50\n",
      "211/211 [==============================] - 64s 301ms/step - loss: 0.5575\n",
      "Epoch 37/50\n",
      "211/211 [==============================] - 63s 300ms/step - loss: 0.5189\n",
      "Epoch 38/50\n",
      "211/211 [==============================] - 63s 301ms/step - loss: 0.4782\n",
      "Epoch 39/50\n",
      "211/211 [==============================] - 63s 300ms/step - loss: 0.4592\n",
      "Epoch 40/50\n",
      "211/211 [==============================] - 63s 301ms/step - loss: 0.4163\n",
      "Epoch 41/50\n",
      "211/211 [==============================] - 63s 301ms/step - loss: 0.4058\n",
      "Epoch 42/50\n",
      "211/211 [==============================] - 64s 301ms/step - loss: 0.3597\n",
      "Epoch 43/50\n",
      "211/211 [==============================] - 64s 301ms/step - loss: 0.3377\n",
      "Epoch 44/50\n",
      "211/211 [==============================] - 63s 300ms/step - loss: 0.3070\n",
      "Epoch 45/50\n",
      "211/211 [==============================] - 64s 302ms/step - loss: 0.2780\n",
      "Epoch 46/50\n",
      "211/211 [==============================] - 64s 302ms/step - loss: 0.2662\n",
      "Epoch 47/50\n",
      "211/211 [==============================] - 64s 303ms/step - loss: 0.2714\n",
      "Epoch 48/50\n",
      "211/211 [==============================] - 63s 300ms/step - loss: 0.2647\n",
      "Epoch 49/50\n",
      "211/211 [==============================] - 64s 304ms/step - loss: 0.2599\n",
      "Epoch 50/50\n",
      "211/211 [==============================] - 63s 301ms/step - loss: 0.2106\n"
     ]
    }
   ],
   "source": [
    "history2 = new_model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=50)\n",
    "\n",
    "model.save('the_great_gatsby_10+50_epochs.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed12ff1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "loss = history2.history['loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8437a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6721032b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f37188a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ced2938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now i will have 52 different probabilities each for the specific character, so i need to have the max probability for each character, for that gonna build a softmax like function;\n",
    "def sample(preds):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds) #exp of log (x), isn't this same as x??\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1) \n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b9a5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e67ab809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a random sentence from the text as seed;\n",
    "start_index = random.randint(0, n_chars - seq_length - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d657a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate generated text and keep adding new predictions and print them out\n",
    "generated = ''\n",
    "sentence = raw_text[start_index: start_index + seq_length]\n",
    "generated += sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06e203bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Seed for our text prediction: \"me, his face close to the window pane, nodding\n",
      "into the twil\"\n"
     ]
    }
   ],
   "source": [
    "print('----- Seed for our text prediction: \"' + sentence + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "555fcedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'me, his face close to the window pane, nodding\\ninto the twil'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969072f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b401d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e, and extait le the garkinc.\n",
      "\n",
      "“i’r goinit gp mle onereo.”\n",
      "\n",
      "he woommble, flom thou"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_10636\\3267894335.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  preds = np.log(preds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d nor elensuly five you leight jornang.\n",
      "\n",
      "“doo’bt, thes becmowourd.”\n",
      "\n",
      "“gasss? a noal down it—onqme, likhalder. “wangs spoped.\n",
      "\n",
      "“wran, i eeparteded s.”\n",
      "\n",
      "“thant, bage tom the ding, and todmant mr. g. he ayfalsstiklima\n",
      "caissbues. a an aboul thit sproturd fint on the stong-goaw.”\n",
      "\n",
      "sut the fon ussess, onlednable the room. \n"
     ]
    }
   ],
   "source": [
    "for i in range(400):   # Number of characters including spaces\n",
    "    x_pred = np.zeros((1, seq_length, n_vocab))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_pred[0, t, char_to_int[char]] = 1.\n",
    "\n",
    "    preds = new_model.predict(x_pred, verbose=0)[0]\n",
    "    next_index = sample(preds)\n",
    "    next_char = int_to_chars[next_index]\n",
    "\n",
    "    generated += next_char\n",
    "    sentence = sentence[1:] + next_char\n",
    "\n",
    "    sys.stdout.write(next_char)\n",
    "    sys.stdout.flush()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f27147",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
